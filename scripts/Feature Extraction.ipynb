{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-8c2hLVgf6Z"
   },
   "outputs": [],
   "source": [
    "import librosa  # need pip install librosa\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from random import random, shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bGrSZAHUgf6d"
   },
   "outputs": [],
   "source": [
    "# Adjust to user\n",
    "audio_path = '../Train_Segments/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ItsTooLate', 'Help', 'YouReallyGotAHoldOnMe', 'ImGoingSlightlyMad', 'BabysInBlack']\n",
      "Loading Segments...\n",
      "Chorusses Loaded\n",
      "Verses Loaded\n",
      "All 170 songs loaded (00:17)\n"
     ]
    }
   ],
   "source": [
    "#List of all songs in the audio directory, without distinction between chorus or verse \n",
    "song_names = list(set([f.split('_')[0] for f in os.listdir(audio_path) if f.endswith('.mp3')]))\n",
    "print(song_names[:5])\n",
    "#Load audio segments\n",
    "start = time.time()\n",
    "print('Loading Segments...')\n",
    "chorusses = [librosa.core.load(audio_path+name+'_chorus.mp3') for name in song_names]\n",
    "print('Chorusses Loaded')\n",
    "verses = [librosa.core.load(audio_path+name+'_verse.mp3') for name in song_names]\n",
    "t = time.time()-start\n",
    "print('Verses Loaded\\nAll {} songs loaded ({:02.0f}:{:02.0f})'.format(len(song_names),t//60,t%60))\n",
    "\n",
    "assert len(verses) == len(chorusses) #we need the same number of chorusses as verses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OwDQB-KFgf6h"
   },
   "outputs": [],
   "source": [
    "def extract_mfcc(y, sr):\n",
    "    mfcc_mat = librosa.feature.mfcc(y, sr, n_mfcc=13)\n",
    "    mfcc_vec = mfcc_mat.mean(axis=1)\n",
    "    return mfcc_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-V-QEa4gf6j"
   },
   "outputs": [],
   "source": [
    "def extract_chroma(y, sr):\n",
    "    chroma_mat = librosa.feature.chroma_stft(y, sr)\n",
    "    return chroma_mat.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g9OJ2gQ-gf6l"
   },
   "outputs": [],
   "source": [
    "def extract_spectrogram(y, sr):\n",
    "    spectro_mat = librosa.feature.melspectrogram(y, sr)\n",
    "    return spectro_mat.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B3kwkhlqgf6o"
   },
   "outputs": [],
   "source": [
    "def extract_centroid(y, sr):\n",
    "    centroid_all = librosa.feature.spectral_centroid(y, sr)\n",
    "    return centroid_all.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tempo(y, sr):\n",
    "    return librosa.beat.tempo(y, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_contrast(y, sr):\n",
    "    contrast = librosa.feature.spectral_contrast(y, sr)\n",
    "    return contrast.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rolloff(y, sr):\n",
    "    rolloff = librosa.feature.spectral_rolloff(y, sr)\n",
    "    return rolloff.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_poly_feats(y, sr):\n",
    "    poly = librosa.feature.poly_features(y, sr, order=3)\n",
    "    return poly.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining feature extractors and group chorus and verse features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YZrFF5YPgf6q"
   },
   "outputs": [],
   "source": [
    "def extract_features(songs):    \n",
    "    '''\n",
    "    Extract all features for each song in songs\n",
    "    '''\n",
    "    feature_names = []\n",
    "    \n",
    "    mfcc_list = [extract_mfcc(y, sr) for y, sr in songs]\n",
    "    feature_names += ['mfcc_{}'.format(i) for i in range(1,np.shape(mfcc_list)[-1]+1)]\n",
    "    \n",
    "    chroma_list = [extract_chroma(y, sr) for y, sr in songs]\n",
    "    feature_names += ['chroma_{}'.format(i) for i in range(1,np.shape(chroma_list)[-1]+1)]\n",
    "\n",
    "    spectro_list = [extract_spectrogram(y, sr) for y, sr in songs]\n",
    "    feature_names += ['spectogram_{}'.format(i) for i in range(1,np.shape(spectro_list)[-1]+1)]\n",
    "    \n",
    "    centroid_list = [extract_centroid(y, sr) for y, sr in songs]\n",
    "    feature_names += ['centroid']\n",
    "    \n",
    "    tempo_list = [extract_tempo(y, sr) for y, sr in songs]\n",
    "    feature_names += ['tempo']\n",
    "    \n",
    "    contrast_list = [extract_contrast(y, sr) for y, sr in songs]\n",
    "    feature_names += ['contrast_{}'.format(i) for i in range(1,np.shape(contrast_list)[-1]+1)]\n",
    "    \n",
    "    rolloff_list = [extract_rolloff(y, sr) for y, sr in songs]\n",
    "    feature_names += ['rolloff']\n",
    "    \n",
    "    poly_list = [extract_poly_feats(y, sr) for y, sr in songs]\n",
    "    feature_names += ['polynomial_coef_{}'.format(i) for i in range(1,np.shape(poly_list)[-1]+1)]\n",
    "    \n",
    "    len_list = [[len(y)] for y,_ in songs]\n",
    "    feature_names += ['segment length']\n",
    "    \n",
    "    \n",
    "    features = np.concatenate((mfcc_list, \n",
    "                               chroma_list,\n",
    "                               spectro_list,\n",
    "                               centroid_list,\n",
    "                               tempo_list,\n",
    "                               contrast_list,\n",
    "                               rolloff_list,\n",
    "                               poly_list,\n",
    "                               len_list,\n",
    "                              ), axis=1)\n",
    "    \n",
    "    return features, feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting chorus features...\n",
      "Extracting verse features...\n",
      "Done! (02:02)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "print('Extracting chorus features...')\n",
    "c_features, feature_names = extract_features(chorusses)\n",
    "\n",
    "print('Extracting verse features...')\n",
    "v_features,_ = extract_features(verses)\n",
    "\n",
    "t = int(time.time()-start)\n",
    "print('Done! ({:02.0f}:{:02.0f})'.format(t//60,t%60))\n",
    "\n",
    "with open('../chorus_features.p', 'wb') as f:\n",
    "    pickle.dump(c_features, f)\n",
    "with open('../verse_features.p', 'wb') as f:\n",
    "    pickle.dump(v_features, f)\n",
    "with open('../feature_names.p', 'wb') as f:\n",
    "    pickle.dump(feature_names, f)\n",
    "with open('../song_names.p', 'wb') as f:\n",
    "    pickle.dump(song_names, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Features.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
